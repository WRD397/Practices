{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-04-21T12:50:21.277989Z","iopub.execute_input":"2023-04-21T12:50:21.278492Z","iopub.status.idle":"2023-04-21T12:50:21.310955Z","shell.execute_reply.started":"2023-04-21T12:50:21.278429Z","shell.execute_reply":"2023-04-21T12:50:21.309696Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"# Diffusers (5 GB)","metadata":{}},{"cell_type":"code","source":"!conda install -c pytorch torchvision cudatoolkit=10.1 pytorch -y","metadata":{"execution":{"iopub.status.busy":"2023-04-21T13:34:26.105472Z","iopub.execute_input":"2023-04-21T13:34:26.105929Z","iopub.status.idle":"2023-04-21T13:42:34.189804Z","shell.execute_reply.started":"2023-04-21T13:34:26.105891Z","shell.execute_reply":"2023-04-21T13:42:34.188240Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Collecting package metadata (current_repodata.json): done\nSolving environment: done\n\n\n==> WARNING: A newer version of conda exists. <==\n  current version: 22.9.0\n  latest version: 23.3.1\n\nPlease update conda by running\n\n    $ conda update -n base -c conda-forge conda\n\n\n\n## Package Plan ##\n\n  environment location: /opt/conda\n\n  added / updated specs:\n    - cudatoolkit=10.1\n    - pytorch\n    - torchvision\n\n\nThe following packages will be downloaded:\n\n    package                    |            build\n    ---------------------------|-----------------\n    aom-3.5.0                  |       h27087fc_0         2.7 MB  conda-forge\n    cudatoolkit-10.1.243       |       h036e899_8       427.4 MB  nvidia\n    ffmpeg-4.4.2               | gpl_h8dda1f0_112         8.9 MB  conda-forge\n    future-0.18.2              |   py37h89c1867_5         713 KB  conda-forge\n    gmp-6.2.1                  |       h58526e2_0         806 KB  conda-forge\n    gnutls-3.7.8               |       hf3e180e_0         2.2 MB  conda-forge\n    implicit-0.5.2             |   py37h648ce6a_1         805 KB  conda-forge\n    lame-3.100                 |    h166bdaf_1003         496 KB  conda-forge\n    libdrm-2.4.114             |       h166bdaf_0         298 KB  conda-forge\n    libidn2-2.3.4              |       h166bdaf_0         157 KB  conda-forge\n    libpciaccess-0.17          |       h166bdaf_0          39 KB  conda-forge\n    libtasn1-4.19.0            |       h166bdaf_0         114 KB  conda-forge\n    libunistring-0.9.10        |       h7f98852_0         1.4 MB  conda-forge\n    libva-2.18.0               |       h0b41bf4_0         182 KB  conda-forge\n    libvpx-1.11.0              |       h9c3ff4c_3         1.1 MB  conda-forge\n    nettle-3.8.1               |       hc379101_1         1.1 MB  conda-forge\n    ninja-1.11.1               |       h924138e_0         2.1 MB  conda-forge\n    openh264-2.3.1             |       hcb278e6_2         702 KB  conda-forge\n    p11-kit-0.24.1             |       hc5aa10d_0         4.5 MB  conda-forge\n    pytorch-1.12.1             |cpu_py37h9dbd814_1        49.2 MB\n    pyyaml-6.0                 |   py37h540881e_4         178 KB  conda-forge\n    svt-av1-1.4.1              |       hcb278e6_0         2.4 MB  conda-forge\n    torchvision-0.12.0         |cpu_py37hb263d47_1         7.5 MB  conda-forge\n    x264-1!164.3095            |       h166bdaf_2         877 KB  conda-forge\n    x265-3.5                   |       h924138e_3         3.2 MB  conda-forge\n    xorg-fixesproto-5.0        |    h7f98852_1002           9 KB  conda-forge\n    xorg-libxfixes-5.0.3       |    h7f98852_1004          18 KB  conda-forge\n    ------------------------------------------------------------\n                                           Total:       519.0 MB\n\nThe following NEW packages will be INSTALLED:\n\n  aom                conda-forge/linux-64::aom-3.5.0-h27087fc_0 None\n  ffmpeg             conda-forge/linux-64::ffmpeg-4.4.2-gpl_h8dda1f0_112 None\n  future             conda-forge/linux-64::future-0.18.2-py37h89c1867_5 None\n  gmp                conda-forge/linux-64::gmp-6.2.1-h58526e2_0 None\n  gnutls             conda-forge/linux-64::gnutls-3.7.8-hf3e180e_0 None\n  lame               conda-forge/linux-64::lame-3.100-h166bdaf_1003 None\n  libdrm             conda-forge/linux-64::libdrm-2.4.114-h166bdaf_0 None\n  libidn2            conda-forge/linux-64::libidn2-2.3.4-h166bdaf_0 None\n  libpciaccess       conda-forge/linux-64::libpciaccess-0.17-h166bdaf_0 None\n  libtasn1           conda-forge/linux-64::libtasn1-4.19.0-h166bdaf_0 None\n  libunistring       conda-forge/linux-64::libunistring-0.9.10-h7f98852_0 None\n  libva              conda-forge/linux-64::libva-2.18.0-h0b41bf4_0 None\n  libvpx             conda-forge/linux-64::libvpx-1.11.0-h9c3ff4c_3 None\n  nettle             conda-forge/linux-64::nettle-3.8.1-hc379101_1 None\n  ninja              conda-forge/linux-64::ninja-1.11.1-h924138e_0 None\n  openh264           conda-forge/linux-64::openh264-2.3.1-hcb278e6_2 None\n  p11-kit            conda-forge/linux-64::p11-kit-0.24.1-hc5aa10d_0 None\n  pytorch            pkgs/main/linux-64::pytorch-1.12.1-cpu_py37h9dbd814_1 None\n  pyyaml             conda-forge/linux-64::pyyaml-6.0-py37h540881e_4 None\n  svt-av1            conda-forge/linux-64::svt-av1-1.4.1-hcb278e6_0 None\n  torchvision        conda-forge/linux-64::torchvision-0.12.0-cpu_py37hb263d47_1 None\n  x264               conda-forge/linux-64::x264-1!164.3095-h166bdaf_2 None\n  x265               conda-forge/linux-64::x265-3.5-h924138e_3 None\n  xorg-fixesproto    conda-forge/linux-64::xorg-fixesproto-5.0-h7f98852_1002 None\n  xorg-libxfixes     conda-forge/linux-64::xorg-libxfixes-5.0.3-h7f98852_1004 None\n\nThe following packages will be DOWNGRADED:\n\n  cudatoolkit                            11.7.0-hd8887f6_10 --> 10.1.243-h036e899_8 None\n  implicit                             0.5.2-py37hac9ef86_1 --> 0.5.2-py37h648ce6a_1 None\n\n\n\nDownloading and Extracting Packages\npytorch-1.12.1       | 49.2 MB   | ##################################### | 100% \nx264-1!164.3095      | 877 KB    | ##################################### | 100% \nlibdrm-2.4.114       | 298 KB    | ##################################### | 100% \ngmp-6.2.1            | 806 KB    | ##################################### | 100% \nlibidn2-2.3.4        | 157 KB    | ##################################### | 100% \nlibtasn1-4.19.0      | 114 KB    | ##################################### | 100% \nopenh264-2.3.1       | 702 KB    | ##################################### | 100% \nfuture-0.18.2        | 713 KB    | ##################################### | 100% \ngnutls-3.7.8         | 2.2 MB    | ##################################### | 100% \np11-kit-0.24.1       | 4.5 MB    | ##################################### | 100% \nlibunistring-0.9.10  | 1.4 MB    | ##################################### | 100% \nx265-3.5             | 3.2 MB    | ##################################### | 100% \nxorg-fixesproto-5.0  | 9 KB      | ##################################### | 100% \nlibpciaccess-0.17    | 39 KB     | ##################################### | 100% \nninja-1.11.1         | 2.1 MB    | ##################################### | 100% \nsvt-av1-1.4.1        | 2.4 MB    | ##################################### | 100% \nffmpeg-4.4.2         | 8.9 MB    | ##################################### | 100% \naom-3.5.0            | 2.7 MB    | ##################################### | 100% \nimplicit-0.5.2       | 805 KB    | ##################################### | 100% \ncudatoolkit-10.1.243 | 427.4 MB  | ##################################### | 100% \nlibvpx-1.11.0        | 1.1 MB    | ##################################### | 100% \nlibva-2.18.0         | 182 KB    | ##################################### | 100% \npyyaml-6.0           | 178 KB    | ##################################### | 100% \nlame-3.100           | 496 KB    | ##################################### | 100% \ntorchvision-0.12.0   | 7.5 MB    | ##################################### | 100% \nnettle-3.8.1         | 1.1 MB    | ##################################### | 100% \nxorg-libxfixes-5.0.3 | 18 KB     | ##################################### | 100% \nPreparing transaction: done\nVerifying transaction: done\nExecuting transaction: | By downloading and using the CUDA Toolkit conda packages, you accept the terms and conditions of the CUDA End User License Agreement (EULA): https://docs.nvidia.com/cuda/eula/index.html\n\ndone\nRetrieving notices: ...working... done\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install diffusers","metadata":{"execution":{"iopub.status.busy":"2023-04-21T13:04:00.289805Z","iopub.execute_input":"2023-04-21T13:04:00.290224Z","iopub.status.idle":"2023-04-21T13:04:14.244159Z","shell.execute_reply.started":"2023-04-21T13:04:00.290191Z","shell.execute_reply":"2023-04-21T13:04:14.242606Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Collecting diffusers\n  Downloading diffusers-0.15.1-py3-none-any.whl (851 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m852.0/852.0 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from diffusers) (3.9.0)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from diffusers) (2021.11.10)\nRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from diffusers) (2.28.2)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from diffusers) (1.21.6)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from diffusers) (4.11.4)\nRequirement already satisfied: Pillow in /opt/conda/lib/python3.7/site-packages (from diffusers) (9.4.0)\nRequirement already satisfied: huggingface-hub>=0.13.2 in /opt/conda/lib/python3.7/site-packages (from diffusers) (0.13.3)\nRequirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub>=0.13.2->diffusers) (4.64.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub>=0.13.2->diffusers) (4.4.0)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub>=0.13.2->diffusers) (6.0)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub>=0.13.2->diffusers) (23.0)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->diffusers) (3.11.0)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->diffusers) (2022.12.7)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->diffusers) (3.4)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->diffusers) (1.26.14)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->diffusers) (2.1.1)\nInstalling collected packages: diffusers\nSuccessfully installed diffusers-0.15.1\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"from diffusers import StableDiffusionPipeline\nimport torch\n\nmodel_id = \"runwayml/stable-diffusion-v1-5\"\npipe = StableDiffusionPipeline.from_pretrained(model_id, torch_dtype=torch.float16)\npipe = pipe.to(\"cuda\")\n\nprompt = \"a photo of an astronaut riding a horse on mars\"\nimage = pipe(prompt).images[0]      \nimage.save(\"astronaut_rides_horse.png\")","metadata":{"execution":{"iopub.status.busy":"2023-04-21T13:52:20.010648Z","iopub.execute_input":"2023-04-21T13:52:20.011750Z","iopub.status.idle":"2023-04-21T13:52:58.916623Z","shell.execute_reply.started":"2023-04-21T13:52:20.011698Z","shell.execute_reply":"2023-04-21T13:52:58.915118Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stderr","text":"`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_27/299203927.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"runwayml/stable-diffusion-v1-5\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpipe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStableDiffusionPipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mpipe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprompt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"a photo of an astronaut riding a horse on mars\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/diffusers/pipelines/pipeline_utils.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, torch_device, torch_dtype, silence_dtype_warnings)\u001b[0m\n\u001b[1;32m    641\u001b[0m         \u001b[0mis_offloaded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline_is_offloaded\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mpipeline_is_sequentially_offloaded\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 643\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch_device\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    644\u001b[0m             if (\n\u001b[1;32m    645\u001b[0m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat16\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    985\u001b[0m         \"\"\"\n\u001b[1;32m    986\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_full_backward_hook\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 987\u001b[0;31m             raise RuntimeError(\"Cannot use both regular backward hooks and full backward hooks on a \"\n\u001b[0m\u001b[1;32m    988\u001b[0m                                \"single Module. Please use only one of them.\")\n\u001b[1;32m    989\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    637\u001b[0m         \u001b[0mReturns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    638\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 639\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    640\u001b[0m         \u001b[0mExample\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    637\u001b[0m         \u001b[0mReturns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    638\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 639\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    640\u001b[0m         \u001b[0mExample\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    660\u001b[0m               \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    661\u001b[0m             )\n\u001b[0;32m--> 662\u001b[0;31m             Sequential(\n\u001b[0m\u001b[1;32m    663\u001b[0m               \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    664\u001b[0m               \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    983\u001b[0m                 \u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 985\u001b[0;31m         \"\"\"\n\u001b[0m\u001b[1;32m    986\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_full_backward_hook\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m             raise RuntimeError(\"Cannot use both regular backward hooks and full backward hooks on a \"\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0;31m# we need to just return without initializing in that case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0;31m# However, we must not let any *other* threads in!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0m_tls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_initializing\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcalls\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_lazy_seed_tracker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_calls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"],"ename":"AssertionError","evalue":"Torch not compiled with CUDA enabled","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}